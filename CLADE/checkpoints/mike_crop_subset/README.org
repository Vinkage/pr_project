#+LATEX_CLASS: notes

* Training command and details

The command I used was mostly adapted from the README file in the sean
directory. The paths to the images and labels were relative paths to the 2000
training images and labels I randomly (seeded) sampled from the CelebA-HQ
dataset. As with SEAN these were cropped to 256x256 during training.

#+BEGIN_SRC shell
python3 train.py --name mike_crop_subset --load_size 256 --crop_size 256 --dataset_mode custom --label_dir path/to/my/train/labels --image_dir path/to/my/train/images --label_nc 19 --no_instance --batchSize 2 --norm_mode clade
#+END_SRC

The difference with the SEAN command is that I enabled the CLADE norm_mode, which is specific to CLADE without it SPADE resblks are used.

#+BEGIN_SRC python
# From CLADE/options/base_options.py
parser.add_argument('--norm_mode', type=str, default='spade', help='[spade | clade]')
#+END_SRC

More info on the training process is stored in text files in this directory.

+ [[file:fid.txt][fid scores]] only contains two lines. Need to find out when the fid is being
  calculated. The options file mentions only that the fid is calculated every 10 epochs.
+ [[file:iter.txt][iter text]] also only contains two lines. It is the 45 epochs times 2000
  iterations the model has been trained for.
+ [[file:loss_log.txt][loss log]] contains the loss function value per epoch.

** Continue training

I continued training using the following command:

#+BEGIN_SRC shell
python3 train.py --name mike_crop_subset --load_size 256 --crop_size 256 --dataset_mode custom --label_dir path/to/my/train/labels --image_dir path/to/my/train/images --label_nc 19 --no_instance --batchSize 8 --norm_mode clade --tf_log --serial_batches
#+END_SRC

I installed the following tenserflow version:

#+BEGIN_SRC shell
pip3 install tensorflow==1.15.0
#+END_SRC

After that for some reason I still had to replace in the visualisation utility =tf= to =tf.compat.v1=

#+BEGIN_SRC python
# visualiser.py

# search and replace
tf
# to
tf.compat.v1
#+END_SRC

When the training was interrupted the out event triggered and the stored iterations were written to a log file.

** loss log plots

I used the tensorboard log files for this, It should also be able to export the
relevant plots to publication quality images.


* Adverserial loss term

The loss function is the same as with the pix2pixHD paper, instead they use a
hinge loss form for the generator loss.

The general GAN loss function in pix2pixHD:

\[
\min_{G} \max_{D} \mathcal{L}(G, D)
\]

we use a multiscale discriminator by default, which you can check in the
multiscale discriminator class in SPADE.

#+BEGIN_SRC python
# From models/networks/discriminator.py
class MultiscaleDiscriminator(BaseNetwork):
    @staticmethod
    def modify_commandline_options(parser, is_train):
        parser.add_argument('--netD_subarch', type=str, default='n_layer',
                            help='architecture of each discriminator')
        parser.add_argument('--num_D', type=int, default=2,
                            help='number of discriminators to be used in multiscale')
        opt, _ = parser.parse_known_args()

        # define properties of each discriminator of the multiscale discriminator
        subnetD = util.find_class_in_module(opt.netD_subarch + 'discriminator',
                                            'models.networks.discriminator')
        subnetD.modify_commandline_options(parser, is_train)

        return parser
# [...]
#+END_SRC

So the general loss form is actually (also in SEAN/SPADE),

\[
\min_{E,G} \max_{D_1 , D_2} \sum_{k=1,2}^{} \mathcal{ L }_{GAN}(E,G, D_{k})
\]

which is the minimax game objective. The objective function \( \mathcal{L}\) is given by,

\[
\mathcal{L}_{GAN}(G,D) = \mathbb{E}_{\left( \boldsymbol{s,x}\right)} \left[ \log D(\boldsymbol{s,x}) \right] + \mathbb{E}_{\boldsymbol{s}} \left[ \log(1 - D(\boldsymbol{s} , G(\boldsymbol{s}))) \right]
\]

Where \( s\) is the label map, and \( x\) is the image.

Note that \( D\) is a (set of) fully convolutional network(s) with a sigmoidal activation
function at the end (only in pix2pix paper, or original gan_mode loss in SPADE
project). This means that the range of \( D\) should be \( \left[ 0,1\right] \).
Where /one/ means real and /zero/ means fake.

** Hinge version :ATTACH:
:PROPERTIES:
:ID:       e165e1c2-8e9a-4632-8752-d824494cab21
:END:

Now in later papers (SPADE and its derivatives) a hinge form was used, without
any sigmoid predictions. This is best explained in the SEAN paper,

\begin{align}
\mathcal{ L }_{GAN} &= \mathbb{E}_{} \left[ \max(0,1 - D_{k}(\boldsymbol{s,x})) \right] \tag*{\{D\_real\} }\\
 &+ \mathbb{E}_{} \left[ \max(0, 1 + D_{k}(\boldsymbol{s,},G(\boldsymbol{s}))) \right] \tag*{\{D\_fake\} }
\end{align}

Where again \( s\) is the label map and \( x\) is the real image. You can see
that there are two hinge terms, the real and fake discriminator loss. The curly
braces on the right gives how the loss log file refers to these terms. It is
also important to note that these expected values are calculated per mini-batch
cite:limGeometricGAN2017. Meaning that low batch size would not accurately
represent the separating hyperplane. But given enough time it still would find
an optimum.

We also have two-scale discriminators, so the value reported in loss\_log.txt is
actually the mean of the two

This is equivalent to the following (Zhang et al. 2019: SAGAN):

\begin{align}
\mathcal{ L }_{D} &= - \mathbb{E}_{(\boldsymbol{s,x})} \left[ \min(0, -1 + D(\boldsymbol{s,x})) \right] \tag*{\{D\_real\} }\\
 &- \mathbb{E}_{s} \left[ \min(0, -1 - D(G(\boldsymbol{s}) , \boldsymbol{s})) \right] \tag*{\{D\_fake\} }\\
\mathcal{ L }_{G} &= - \mathbb{E}_{\boldsymbol{s} } \left[ D(G(\boldsymbol{s}) , \boldsymbol{s}) \right] \tag*{\{GAN\} }
\end{align}

Where \( \mathcal{ L }_{G}\) is the generator loss, this is important, because
we are training stepwise the generator and discriminator. One step the
\(\mathcal{ L }_{D}\) is computed and \( \mathcal{ L }_{G}\) in the other.


It can be shown that this equation converges to \(2 \) , and that is equivalent
to pushing the generated image to the separating hyperplane, and optimising the
hyperplane margins for the discriminator (geometric gan paper).

The intuition for this is that when the probability distribution of the real
images and fake images are equivalent, or the reverse KL-divergence \( KL \left[ p_{g} || q_{data}\right]\)
is minimised cite:miyatoSpectralNormalizationGenerative2018. Especially the
example of learning parallel lines at the end of section 3 of the paper was
nice. The paper also gives the geometric intuition for the hinge loss



[[attachment:_20210104_131213Screenshot 2021-01-04 at 13.11.45.png]]

As you can see the discriminator tries to push away from the hyperplane where \(
D = 0\),
and the generator tries to push towards the \( 0\) .


bibliographystyle:unsrt
bibliography:../../../../../../Dropbox/bibliography/references.bib
