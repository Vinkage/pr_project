{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CLADE.ipynb",
      "provenance": [],
<<<<<<< HEAD
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
=======
      "collapsed_sections": [
        "qycfHLHqkm3G",
        "7uUq3Tb3_che"
      ],
      "toc_visible": true,
      "mount_file_id": "15ALT7dAG71fnBVMpe63bz6zk_j5uWcHT",
      "authorship_tag": "ABX9TyNLR1hvYyz6Yfz/P4rmBW7Q"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
>>>>>>> main
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KHj1kX7z_B2",
<<<<<<< HEAD
        "outputId": "16d6f6ca-afaa-4cd1-ad0f-05ddc5876b9b"
=======
        "outputId": "5b950ffc-4322-4644-a38d-1b354aa8df9c"
>>>>>>> main
      },
      "source": [
        "# Check nvidia and nvcc cuda compiler\r\n",
        "\r\n",
        "!nvidia-smi\r\n",
        "!/usr/local/cuda/bin/nvcc --version"
      ],
      "execution_count": null,
<<<<<<< HEAD
=======
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jan 13 18:30:21 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.27.04    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qycfHLHqkm3G"
      },
      "source": [
        "# other"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjZ2jJyr573k",
        "outputId": "5f57eb3b-3440-4d96-c5c3-99f91c3cc381"
      },
      "source": [
        "#1 - setup ssh/user\r\n",
        "\r\n",
        "\r\n",
        "#Generate a random root password\r\n",
        "import random, string\r\n",
        "password = ''.join(random.choice(string.ascii_letters + string.digits) for i in range(30))\r\n",
        "\r\n",
        "\r\n",
        "#Setup sshd\r\n",
        "! apt-get install -qq -o=Dpkg::Use-Pty=0 openssh-server pwgen > /dev/null\r\n",
        "\r\n",
        "#Set root password\r\n",
        "! echo root:$password | chpasswd\r\n",
        "! mkdir -p /var/run/sshd\r\n",
        "! echo \"PermitRootLogin yes\" >> /etc/ssh/sshd_config\r\n",
        "! echo \"PasswordAuthentication yes\" >> /etc/ssh/sshd_config\r\n",
        "\r\n",
        "print(\"username: root\")\r\n",
        "print(\"password: \", password)\r\n",
        "\r\n",
        "#Run sshd\r\n",
        "get_ipython().system_raw('/usr/sbin/sshd -D &')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "username: root\n",
            "password:  ZdpHv30jxlCj165DIlnFtJl0l2HunC\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQuLE8oc5_8J"
      },
      "source": [
        "# 2 - Download Ngrok\r\n",
        "\r\n",
        "! wget -q -c -nc https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\r\n",
        "! unzip -qq -n ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": null,
>>>>>>> main
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
<<<<<<< HEAD
        "id": "Mdutxc2H57Wv",
        "outputId": "90df10db-9ac8-4892-950a-8c71523f1e20"
      },
      "source": [
        "!git clone https://github.com/tzt101/CLADE.git CLADE\r\n",
        "\r\n",
        "# file = \"/content/CLADE/requirements.txt\"\r\n",
        "# with open(file) as f:\r\n",
        "#   lines = f.readlines()\r\n",
        "# lines[0] = \"torch==1.6.0\\n\"\r\n",
        "# with open(file, \"w\") as f:\r\n",
        "#   f.writelines(lines)\r\n",
        "\r\n",
        "# !pip install -r CLADE/requirements.txt"
=======
        "id": "yluMMWSN6B9G",
        "outputId": "4e3a5e11-ecd8-4686-9952-877dc4a0d5e0"
      },
      "source": [
        "# 3 - setup Ngrok - authtoken\r\n",
        "\r\n",
        "#Ask token\r\n",
        "print(\"Get your authtoken from https://dashboard.ngrok.com/auth\")\r\n",
        "import getpass\r\n",
        "authtoken = getpass.getpass()\r\n",
        "\r\n",
        "#Create tunnel\r\n",
        "get_ipython().system_raw('./ngrok authtoken $authtoken && ./ngrok tcp 22 &')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Get your authtoken from https://dashboard.ngrok.com/auth\n",
            "··········\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTWCZ4sZ6GNs",
        "outputId": "8b924a30-f2ea-4e5d-d188-225c74cd1db9"
      },
      "source": [
        "# When done with the ssh, kill Ngrok\r\n",
        "\r\n",
        "!kill $(ps aux | grep './ngrok' | awk '{print $2}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUCACM6rktEj"
      },
      "source": [
        "# Clade"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mdutxc2H57Wv"
      },
      "source": [
        "# !rm -rf pr_proj\r\n",
        "!git clone -b main https://github.com/Vinkage/pr_project.git pr_proj\r\n",
        "\r\n",
        "!pip install -r pr_proj/SPADE/requirements.txt"
>>>>>>> main
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDJ4L2vZSZbX",
<<<<<<< HEAD
        "outputId": "02c84f36-ade8-4fd7-e515-4b528e60c269"
      },
      "source": [
        "# torch=1.6.0\r\n",
        "# torchvision\r\n",
        "# dominate>=2.3.1\r\n",
        "# !pip install dill\r\n",
        "# !pip install scikit-image\r\n",
        "!pip install dominate"
      ],
      "execution_count": null,
      "outputs": []
=======
        "outputId": "ab8dba94-1dc5-4e79-9881-b0696c94c149"
      },
      "source": [
        "# !pip install torch --upgrade\r\n",
        "# !pip install torchvision\r\n",
        "# dominate>=2.3.1\r\n",
        "# !pip install dill\r\n",
        "# !pip install scikit-image\r\n",
        "# !pip install dominate"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting dominate\n",
            "  Downloading https://files.pythonhosted.org/packages/ef/a8/4354f8122c39e35516a2708746d89db5e339c867abbd8e0179bccee4b7f9/dominate-2.6.0-py2.py3-none-any.whl\n",
            "Installing collected packages: dominate\n",
            "Successfully installed dominate-2.6.0\n"
          ],
          "name": "stdout"
        }
      ]
>>>>>>> main
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
<<<<<<< HEAD
        "id": "drhBeGCrNR-M",
        "outputId": "7a6b9a0e-036b-461b-e05e-a0cc76e9561e"
      },
      "source": [
        "!python CLADE/train.py --name adeoutdoor_test --dataset_mode ade20koutdoor --dataroot \"Datasets/\" --checkpoints_dir \"CLADE/Checkpoints/\" --batchSize 4"
      ],
      "execution_count": null,
      "outputs": []
=======
        "id": "Xdjke5T4SH7S",
        "outputId": "a59e6733-3a38-420e-9bb2-4636fe452b01"
      },
      "source": [
        "!python /content/pr_proj/SPADE/eval.py --name celeb_gridsearch_2 --dataset \"/content/Datasets/CelebA-HQ/\" --root_path \"/content/pr_proj/SPADE/\" --npz_path \"/content/Datasets/FID_stats.npz\""
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'name': 'celeb_gridsearch_2', 'dataset_path': '/content/Datasets/CelebA-HQ/', 'root_path': '/content/pr_proj/SPADE/', 'npz_path': 'FID_stats.npz'}\n",
            "created temporary directory, resizing images and saving training FID stats /tmp/tmpqovoqjkj\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/pr_proj/SPADE/eval.py\", line 279, in <module>\n",
            "    resize_images_and_save_statistics(grid_experiment = Grid)\n",
            "  File \"/content/pr_proj/SPADE/eval.py\", line 69, in resize_images_and_save_statistics\n",
            "    anti_aliasing=False)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/skimage/transform/_warps.py\", line 166, in resize\n",
            "    preserve_range=preserve_range)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/skimage/transform/_warps.py\", line 863, in warp\n",
            "    cval=cval))\n",
            "  File \"skimage/transform/_warps_cy.pyx\", line 183, in skimage.transform._warps_cy._warp_fast\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py\", line 14, in asarray\n",
            "    @set_module('numpy')\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
>>>>>>> main
    },
    {
      "cell_type": "code",
      "metadata": {
<<<<<<< HEAD
        "id": "GDZlzcAjgQNb"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
=======
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qn1lN8MtSq0",
        "outputId": "0d52d020-6aa8-4454-dd86-ff02af85dbd4"
      },
      "source": [
        "# !python /content/pr_proj/SPADE/eval.py\r\n",
        "\r\n",
        "# !python /content/pr_proj/SPADE/eval.py --name celeb_gridsearch_1 --dataset \"/content/Datasets/CelebA-HQ/\" --root_path \"/content/pr_proj/SPADE/\"\r\n",
        "\r\n",
        "# !python /content/pr_proj/CLADE/calc.py --name Rick_test_adek_subset_small3 --dataset_mode ade20k --dataroot \"Datasets/ADEChallengeData2016/\" --checkpoints_dir \"drive/MyDrive/Pattern recognition project/Checkpoints/\"\r\n",
        "# !python pr_proj/CLADE/train.py --name Rick_test_adek_subset_small2 --dataset_mode ade20k --dataroot \"Datasets/ADEChallengeData2016/\" --checkpoints_dir \"drive/MyDrive/Pattern recognition project/Checkpoints/\""
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'name': 'celeb_gridsearch_1', 'dataset_path': '/content/Datasets/CelebA-HQ/', 'root_path': '/content/pr_proj/SPADE/'}\n",
            "created temporary directory, resizing images and saving training FID stats /tmp/tmp310_mvwh\n",
            "100% 560/560 [02:13<00:00,  4.21it/s]\n",
            "dataset [CustomDataset] of size 28000 was created\n",
            "Network [SPADEGenerator] was created. Total number of parameters: 92.5 million. To see the architecture, do print(network).\n",
            "Network [MultiscaleDiscriminator] was created. Total number of parameters: 1.4 million. To see the architecture, do print(network).\n",
            "create web directory ./checkpoints/celeb_gridsearch_1_search1/web...\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "(epoch: 1, iters: 100, time: 0.432) GAN: 0.865 GAN_Feat: 8.407 VGG: 8.997 D_Fake: 0.520 D_real: 0.871 \n",
            "(epoch: 1, iters: 200, time: 0.449) GAN: 0.318 GAN_Feat: 6.842 VGG: 7.656 D_Fake: 0.332 D_real: 1.320 \n",
            "(epoch: 1, iters: 300, time: 0.444) GAN: 1.225 GAN_Feat: 4.940 VGG: 11.146 D_Fake: 0.201 D_real: 1.143 \n",
            "(epoch: 1, iters: 400, time: 0.446) GAN: 0.622 GAN_Feat: 9.266 VGG: 8.153 D_Fake: 0.669 D_real: 0.217 \n",
            "(epoch: 1, iters: 500, time: 0.445) GAN: 1.187 GAN_Feat: 7.362 VGG: 8.524 D_Fake: 0.222 D_real: 0.769 \n",
            "(epoch: 1, iters: 600, time: 0.475) GAN: 1.389 GAN_Feat: 3.676 VGG: 6.969 D_Fake: 0.177 D_real: 2.672 \n",
            "(epoch: 1, iters: 700, time: 0.452) GAN: 0.964 GAN_Feat: 6.429 VGG: 8.303 D_Fake: 0.372 D_real: 0.835 \n",
            "(epoch: 1, iters: 800, time: 0.447) GAN: 1.351 GAN_Feat: 5.647 VGG: 8.285 D_Fake: 0.097 D_real: 1.982 \n",
            "(epoch: 1, iters: 900, time: 0.446) GAN: 1.264 GAN_Feat: 7.217 VGG: 9.772 D_Fake: 0.158 D_real: 0.622 \n",
            "(epoch: 1, iters: 1000, time: 0.454) GAN: -0.072 GAN_Feat: 7.820 VGG: 8.794 D_Fake: 0.959 D_real: 0.510 \n",
            "(epoch: 1, iters: 1100, time: 0.458) GAN: 0.284 GAN_Feat: 7.128 VGG: 6.988 D_Fake: 0.949 D_real: 0.497 \n",
            "(epoch: 1, iters: 1200, time: 0.449) GAN: 0.810 GAN_Feat: 2.952 VGG: 8.737 D_Fake: 0.410 D_real: 1.200 \n",
            "(epoch: 1, iters: 1300, time: 0.444) GAN: 1.594 GAN_Feat: 4.799 VGG: 8.657 D_Fake: 0.052 D_real: 1.929 \n",
            "Traceback (most recent call last):\n",
            "  File \"/content/pr_proj/SPADE/eval.py\", line 298, in <module>\n",
            "    Grid.search(train_search, train=True)\n",
            "  File \"/content/pr_proj/SPADE/eval.py\", line 240, in search\n",
            "    do_train(arg_opt)\n",
            "  File \"/content/pr_proj/SPADE/train.py\", line 95, in do_train\n",
            "    trainer.run_generator_one_step(data_i)\n",
            "  File \"/content/pr_proj/SPADE/trainers/pix2pix_trainer.py\", line 38, in run_generator_one_step\n",
            "    self.optimizer_G.step()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/autograd/grad_mode.py\", line 26, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\", line 119, in step\n",
            "    group['eps']\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/optim/functional.py\", line 87, in adam\n",
            "    exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1 - beta2)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
>>>>>>> main
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8A_j4zoYgLFx"
      },
      "source": [
        "# Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
<<<<<<< HEAD
        "id": "oIBJfzIaG-76"
=======
        "id": "drhBeGCrNR-M"
      },
      "source": [
        "# !python CLADE/train.py --name Rick_test_adek_subset_small2 --dataset_mode ade20k --dataroot \"Datasets/ADEChallengeData2016/\" --checkpoints_dir \"drive/MyDrive/Pattern recognition project/Checkpoints/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqnwCM0F6BTf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "27358033-69b1-4d3c-b0ff-d0453bb3819e"
      },
      "source": [
        "import zipfile\r\n",
        "import shutil\r\n",
        "with zipfile.ZipFile(\"/content/drive/MyDrive/Pattern_recognition_project/Datasets/celebs.zip\", 'r') as zip_ref:\r\n",
        "  zip_ref.extractall(\"/content/Datasets/\")\r\n",
        "\r\n",
        "shutil.copy2('/content/drive/MyDrive/Pattern_recognition_project/Datasets/FID_stats.npz', '/content/Datasets/FID_stats.npz')\r\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/Datasets/FID_stats.npz'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uUq3Tb3_che"
      },
      "source": [
        "# old"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XejKmbL2hXv3"
>>>>>>> main
      },
      "source": [
        "import urllib.request\r\n",
        "!mkdir Datasets\r\n",
        "# urllib.request.urlretrieve(\"http://data.csail.mit.edu/places/ADEchallenge/ADEChallengeData2016.zip\", \"Datasets/ADEChallengeData2016.zip\")\r\n",
        "# urllib.request.urlretrieve(\"http://images.cocodataset.org/zips/train2017.zip\", \"Datasets/train2017.zip\")\r\n",
        "# urllib.request.urlretrieve(\"http://images.cocodataset.org/annotations/annotations_trainval2017.zip\", \"Datasets/annotations_trainval2017.zip\")\r\n",
        "# urllib.request.urlretrieve(\"http://images.cocodataset.org/zips/val2017.zip\", \"Datasets/val2017.zip\")\r\n",
        "# urllib.request.urlretrieve(\"https://mab.to/7cnM68u20\", \"Datasets/city.zip\")\r\n",
        "\r\n",
        "\r\n",
        "# From drive\r\n",
        "# urllib.request.urlretrieve(\"http://calvin.inf.ed.ac.uk/wp-content/uploads/data/cocostuffdataset/stuffthingmaps_trainval2017.zip\", \"Datasets/stuffthingmaps_trainval2017.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
<<<<<<< HEAD
        "id": "CqnwCM0F6BTf"
      },
      "source": [
        "import zipfile\n",
        "# with zipfile.ZipFile(\"/content/Datasets/ADEChallengeData2016.zip\", 'r') as zip_ref:\n",
        "#   zip_ref.extractall(\"/content/Datasets/\")\n",
        "\n",
        "# with zipfile.ZipFile(\"/content/Datasets/train2017.zip\", 'r') as zip_ref:\n",
        "#   zip_ref.extractall(\"/content/Datasets/\")\n",
        "\n",
        "# with zipfile.ZipFile(\"/content/Datasets/annotations_trainval2017.zip\", 'r') as zip_ref:\n",
        "#   zip_ref.extractall(\"/content/Datasets/\")\n",
        "\n",
        "# with zipfile.ZipFile(\"/content/Datasets/ADEChallengeData2016.zip\", 'r') as zip_ref:\n",
        "#   zip_ref.extractall(\"/content/Datasets/\")\n",
        "\n",
        "# with zipfile.ZipFile(\"drive/MyDrive/Pattern recognition project/Datasets/ADE20K_Outdoor.zip\", 'r') as zip_ref:\n",
        "#   zip_ref.extractall(\"/content/Datasets/\")\n",
        "\n",
        "# with zipfile.ZipFile(\"drive/MyDrive/Pattern recognition project/Datasets/gtFine_trainvaltest.zip\", 'r') as zip_ref:\n",
        "#   zip_ref.extractall(\"/content/Datasets/\")\n",
        "\n",
        "# with zipfile.ZipFile(\"drive/MyDrive/Pattern recognition project/Datasets/stuffthingmaps_trainval2017.zip\", 'r') as zip_ref:\n",
=======
        "id": "GYoXcDKlhUMN"
      },
      "source": [
        "\r\n",
        "# with zipfile.ZipFile(\"/content/Datasets/ADEChallengeData2016.zip\", 'r') as zip_ref:\r\n",
        "#   zip_ref.extractall(\"/content/Datasets/\")\r\n",
        "\r\n",
        "# with zipfile.ZipFile(\"/content/Datasets/train2017.zip\", 'r') as zip_ref:\r\n",
        "#   zip_ref.extractall(\"/content/Datasets/\")\r\n",
        "\r\n",
        "# with zipfile.ZipFile(\"/content/Datasets/annotations_trainval2017.zip\", 'r') as zip_ref:\r\n",
        "#   zip_ref.extractall(\"/content/Datasets/\")\r\n",
        "\r\n",
        "# with zipfile.ZipFile(\"/content/Datasets/ADEChallengeData2016.zip\", 'r') as zip_ref:\r\n",
        "#   zip_ref.extractall(\"/content/Datasets/\")\r\n",
        "\r\n",
        "# with zipfile.ZipFile(\"/content/drive/MyDrive/Pattern_recognition_project/Datasets/ADEChallengeData2016.zip\", 'r') as zip_ref:\r\n",
        "#   zip_ref.extractall(\"/content/Datasets/\")\r\n",
        "\r\n",
        "# with zipfile.ZipFile(\"drive/MyDrive/Pattern recognition project/Datasets/gtFine_trainvaltest.zip\", 'r') as zip_ref:\r\n",
        "#   zip_ref.extractall(\"/content/Datasets/\")\r\n",
        "\r\n",
        "# with zipfile.ZipFile(\"drive/MyDrive/Pattern recognition project/Datasets/stuffthingmaps_trainval2017.zip\", 'r') as zip_ref:\r\n",
>>>>>>> main
        "#   zip_ref.extractall(\"/content/Datasets/stuff/\")"
      ],
      "execution_count": null,
      "outputs": []
<<<<<<< HEAD
=======
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QA-SsgYsvd0Z"
      },
      "source": [
        "file = \"drive/MyDrive/Pattern recognition project/Datasets/subsets/ADEChallengeData2016/sceneCategories.txt\"\r\n",
        "import os\r\n",
        "translate = {}\r\n",
        "translate['train'] = 'training'\r\n",
        "translate['val'] = 'validation'\r\n",
        "with open(file) as f:\r\n",
        "  lines = f.readlines()\r\n",
        "\r\n",
        "categories = {}\r\n",
        "for line in lines:\r\n",
        "  file_name, category = line.split()\r\n",
        "  splitten = file_name.split(\"_\")\r\n",
        "  subcat = splitten[1]\r\n",
        "\r\n",
        "  if subcat not in categories:\r\n",
        "    categories[subcat] = {}\r\n",
        "\r\n",
        "  if category not in categories[subcat]:\r\n",
        "    categories[subcat][category] = []\r\n",
        "\r\n",
        "  categories[subcat][category].append(file_name)\r\n",
        "  # categories[category][file_name] = 0\r\n",
        "\r\n",
        "print(lines)\r\n",
        "\r\n",
        "n = 2\r\n",
        "for i, category in categories.items():\r\n",
        "  for key, values in category.items():\r\n",
        "    count = 0\r\n",
        "    print(key, \": \", len(values))\r\n",
        "    for value in values:\r\n",
        "      if count < n:\r\n",
        "        count += 1\r\n",
        "        continue\r\n",
        "\r\n",
        "      # test = lines.index(value + \" \" + key + \"\\n\")\r\n",
        "      # del lines[test]\r\n",
        "\r\n",
        "      # print(\"drive/MyDrive/Pattern recognition project/Datasets/subsets/ADEChallengeData2016/annotations/\" + translate[i] + \"/\" + value + \".png\")\r\n",
        "      # print(\"drive/MyDrive/Pattern recognition project/Datasets/subsets/ADEChallengeData2016/images/\" + translate[i] + \"/\" + value + \".jpg\")\r\n",
        "      # print(translate[i])\r\n",
        "\r\n",
        "      # os.remove(\"drive/MyDrive/Pattern recognition project/Datasets/subsets/ADEChallengeData2016/annotations/\" + translate[i] + \"/\" + value + \".png\")\r\n",
        "      # os.remove(\"drive/MyDrive/Pattern recognition project/Datasets/subsets/ADEChallengeData2016/images/\" + translate[i] + \"/\" + value + \".jpg\")\r\n",
        "\r\n",
        "# print(lines)  \r\n",
        "\r\n",
        "with open(file, 'w') as file:\r\n",
        "  file.writelines(lines)\r\n",
        "\r\n",
        "\r\n",
        "# print(categories)\r\n",
        "# lines[0] = \"torch==1.6.0\\n\"\r\n",
        "# with open(file, \"w\") as f:\r\n",
        "#   f.writelines(lines)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkXVznzrF8Xs"
      },
      "source": [
        "\r\n",
        "# shutil.copytree('drive/MyDrive/Pattern recognition project/Datasets/subsets/ADEChallengeData2016', '/content/Datasets/ADEChallengeData2016')\r\n",
        "# shutil.copytree('baz', 'foo', dirs_exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2gapJZwgT2O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "outputId": "7b213f99-986b-4f3c-bfb0-1b6748c14f7b"
      },
      "source": [
        "# !python CLADE/datasets/coco_generate_instance_map.py --annotation_file=\"Datasets/annotations/instances_train2017.json\" --input_label_dir=\"Datasets/stuff/train2017/\" --output_instance_dir=\"Datasets/Output/\"\r\n",
        "\r\n",
        "import shutil\r\n",
        "# shutil.make_archive(\"drive/MyDrive/Pattern recognition project/Datasets/subsets/subset\", 'zip', \"drive/MyDrive/Pattern recognition project/Datasets/subsets/ADEChallengeData2016/\")\r\n",
        "# !zip -r /content/file.zip /content/Folder_To_Zip\r\n",
        "\r\n",
        "# from google.colab import files\r\n",
        "# files.download(\"/content/output.zip\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-98352f88f783>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"drive/MyDrive/Pattern recognition project/Datasets/subsets/subset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'zip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"drive/MyDrive/Pattern recognition project/Datasets/subsets/ADEChallengeData2016/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# !zip -r /content/file.zip /content/Folder_To_Zip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/shutil.py\u001b[0m in \u001b[0;36mmake_archive\u001b[0;34m(base_name, format, root_dir, base_dir, verbose, dry_run, owner, group, logger)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mroot_dir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/shutil.py\u001b[0m in \u001b[0;36m_make_zipfile\u001b[0;34m(base_name, base_dir, verbose, dry_run, logger)\u001b[0m\n\u001b[1;32m    702\u001b[0m                     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m                         \u001b[0mzf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"adding '%s'\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/zipfile.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, filename, arcname, compress_type)\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1645\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1646\u001b[0;31m                 \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwritestr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzinfo_or_arcname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompress_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/shutil.py\u001b[0m in \u001b[0;36mcopyfileobj\u001b[0;34m(fsrc, fdst, length)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;34m\"\"\"copy data from file-like object fsrc to file-like object fdst\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hM1Qq0hqAiZ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c93b9bf-d536-41b9-abc1-b08e32a971d1"
      },
      "source": [
        "!pip install python-rclone"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python-rclone\n",
            "  Downloading https://files.pythonhosted.org/packages/0e/fd/55fc62562c8c6eff7f9a9a9c2a35167ad736362d09ec49c8f4d47586e808/python_rclone-0.0.2-py3-none-any.whl\n",
            "Installing collected packages: python-rclone\n",
            "Successfully installed python-rclone-0.0.2\n"
          ],
          "name": "stdout"
        }
      ]
>>>>>>> main
    }
  ]
}